"""
Evaluation Script
Evaluates fine-tuned automotive expert model on test queries.
"""

import sys
import os

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

import torch
import config
from utils.helpers import set_seed, print_gpu_info, print_banner
from models.model_loader import ModelLoader
from evaluation.evaluator import evaluate_model


def main():
    """Main evaluation pipeline."""
    
    print_banner("üöó AUTOMOTIVE EXPERT ASSISTANT - EVALUATION")
    
    # Set seed for reproducibility
    set_seed(config.SEED)
    
    # Print GPU info
    print_gpu_info()
    
    # ========================================================================
    # Load Fine-Tuned Model
    # ========================================================================
    print_banner("LOADING FINE-TUNED MODEL")
    
    model_path = config.MODEL_SAVE_DIR
    
    # Check if model exists
    if not os.path.exists(model_path):
        print(f"‚ùå Model not found at: {model_path}")
        print(f"\nPlease train the model first:")
        print(f"  python scripts/train.py")
        sys.exit(1)
    
    print(f"Loading model from: {model_path}")
    
    try:
        model, tokenizer = ModelLoader.load_for_inference(model_path)
    except Exception as e:
        print(f"‚ùå Failed to load model: {e}")
        print("\nMake sure you have completed training successfully.")
        sys.exit(1)
    
    # ========================================================================
    # Run Evaluation
    # ========================================================================
    print_banner("RUNNING EVALUATION")
    
    print("Testing model on automotive domain questions...")
    print("This will evaluate the model on predefined automotive queries.\n")
    
    results = evaluate_model(model, tokenizer)
    
    # ========================================================================
    # Summary
    # ========================================================================
    print_banner("EVALUATION COMPLETE")
    
    print(f"‚úì Evaluated on {len(results)} queries")
    print(f"\nResults show the model's ability to:")
    print(f"  ‚Ä¢ Explain automotive concepts")
    print(f"  ‚Ä¢ Provide buying recommendations")
    print(f"  ‚Ä¢ Compare vehicles")
    print(f"  ‚Ä¢ Answer maintenance questions")
    print(f"  ‚Ä¢ Discuss electric and hybrid technologies")
    
    print(f"\nüöÄ Next Steps:")
    print(f"  ‚Ä¢ Try interactive chat: python scripts/inference.py")
    print(f"  ‚Ä¢ Test with your own questions in chat mode")
    print(f"  ‚Ä¢ Review training logs: tensorboard --logdir {config.LOGS_DIR}")
    
    print("\n" + "="*70 + "\n")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Evaluation interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Evaluation failed with error:")
        print(f"{e}\n")
        import traceback
        traceback.print_exc()
        sys.exit(1)
